---
title: about
date: 2020-06-06 00:45:22
---

# About the founder

Hi! I am Jorge, from Mexico City. I like to see myself as an engineer that focuses a lot on modern Machine Learning these days. If you want to know more about me, please check my personal website.

# The short story behind the blog

The _ML summaries_ started in early 2020. My motivation was very simple: help others to understand ML best papers without struggling too much. Because let's be honest... we usually don't know the topics at the same level that the authors do. That causes us to spend a lot of time going into the details or assumptions that are not always clear to everyone.

The main goal is to provide you with a review of the paper and its most important references so that you don't have to start from scratch. Ideally, reading these summaries should also give a good starting point on how to implement it. Let me know in the comments if I accomplished these two goals :).

# The long story...

I think that the situation that triggered this blog dates from 2017. I entered the ML ecosystem that year, and I was definitely not into it before. I had finished a bachelor's in computer science in 2013, and I had worked as a software engineer for a few years. Then, I decided to pursue a master's in Data Science.

You might say that there's nothing weird with that because ML relies a lot on computer science. Well, the problem is that the formation of a computer scientist around 2010 had priorities that do not always align with what ML requires. I think that the main aspiration of us, the average bachelor's students of computer science, was to become a developer because that's what the job market needed. So we had to learn about data structures, programming frameworks, networking, software engineering, etc. All this is actually pretty cool to learn, but it also means that even if you had a good mathematical background or were lucky enough to have learned the basic ML, it was definitely not something you used while learning Java EE.

So, I really struggled when I started with DS and ML. 5 years had passed since my last mathematical course and I felt like my brain had learned to think more in systems than in abstract equations. Things got really nasty when the syllabus needed me to understand from one day to the other what softmax, backpropagation, cross-entropy, Bayesian learning, LSTMs, reinforcement learning, and uncountable other concepts were. Eventually, I learned them but during the journey, I realized that my ability to think in systems (i.e., boxes connected through inputs and outputs) actually helped me to outstand a bit in ML. I also realized that I was not the only one who benefits from that way of thinking. 

The _ML summaries_ blog is born with that experience in mind. I am aware that scientific disclosure has its own procedures and that papers follow a strict guideline. However, when it comes to learning, a slightly different outline is desired because not everyone has the same background. That is particularly important to keep in mind now that the DS boom brings to the community people with diverse formations that will require us to explain and learn ML differently to enrich the field.

I hope that this explanation helps to understand the key idea of the ML summaries blog. If you feel my story relatable in any way, then you could also join me in this quest! I'll be happy to work together!

Enjoy the summaries and good luck with your ML journey!
